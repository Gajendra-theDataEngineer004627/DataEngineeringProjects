{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtrth6we9jf/QL/zM0ZkAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gajendra-theDataEngineer004627/DataEngineeringProjects/blob/ChessChampionshipProject/DE_Solutions_GRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_uWVNb5Ai3V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a39483d-8b0c-41b7-928d-6aa994a3eb91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connected to clou\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [2 InRelease 15.6 kB/114 kB 14%] [Connecting to security.ubuntu.com] [Connec\r0% [Connecting to security.ubuntu.com (91.189.91.39)] [Connecting to ppa.launch\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "\r0% [4 InRelease 15.6 kB/108 kB 14%] [Waiting for headers] [Connecting to ppa.la\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "\r0% [4 InRelease 82.0 kB/108 kB 76%] [Waiting for headers] [Connecting to ppa.la\r                                                                               \r0% [Waiting for headers] [Connecting to ppa.launchpad.net (185.125.190.52)]\r                                                                           \rGet:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,347 kB]\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [32.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,372 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,084 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,677 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,072 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [29.3 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,866 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,536 kB]\n",
            "Fetched 15.4 MB in 2s (7,515 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "af-JE2bHjxxM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "Ne1MHHMdkO7x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "XgZd6iOskebJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "jnjdlT4CkjII"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "ACgBCh7PktWA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = (SparkSession\n",
        " .builder\n",
        " .appName(\"<app_name>\")\n",
        " .getOrCreate())\n"
      ],
      "metadata": {
        "id": "ob8j-c-ckx4I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to doanload data files from the google drive\n",
        "import gdown\n",
        "def downloadfiles_fromFolder() :\n",
        "    url = \"https://drive.google.com/drive/folders/1QgWPHV_l25Ui9L7et8mkZohAOG59UTkQ\"   # can also be used input()\n",
        "    if url.split(\"/\")[-1]== \"?usp=sharing\":\n",
        "       url = url.replace(\"?usp=sharing\",\"\")\n",
        "    gdown.download_folder(url, output=\"/content\")\n",
        "\n",
        "downloadfiles_fromFolder()"
      ],
      "metadata": {
        "id": "egBrBPncpxL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the datasets for each data files and understanding the data\n",
        "\n",
        "chess_wc_history_game_info = spark.read.load(\"/content/chess_wc_history_game_info.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "chess_wc_history_moves = spark.read.load(\"/content/chess_wc_history_moves.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "eco_codes = spark.read.load(\"/content/eco_codes.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n"
      ],
      "metadata": {
        "id": "ciwD1tV_w6G4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the top 10 records are properly loaded or not\n",
        "# print(chess_wc_history_moves.head())\n",
        "# print(eco_codes.head())\n",
        "# print(chess_wc_history_game_info.head())"
      ],
      "metadata": {
        "id": "44qmU1Vo0eSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def spark_dataframes_to_csv(dataframes, drive_path):\n",
        "    # Mount Google Drive if not already mounted\n",
        "    if not os.path.isdir('/content/gdrive'):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/gdrive')\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    directory_path = '/content/gdrive/MyDrive/' + drive_path\n",
        "    if not os.path.exists(directory_path):\n",
        "        os.makedirs(directory_path)\n",
        "\n",
        "    # Convert Spark DataFrames to Pandas DataFrames and save as CSV\n",
        "    for i, dataframe in enumerate(dataframes, start=1):\n",
        "        pandas_df = dataframe.toPandas()\n",
        "        file_path = f'{directory_path}/df{i}.csv'\n",
        "        pandas_df.to_csv(file_path, index=False)\n",
        "        print(f\"DataFrame {i} saved as {file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "cpjW8CvBVq5D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating temporary view for data manupulations\n",
        "chess_wc_history_moves.createOrReplaceTempView(\"chess_wc_history_movesTemp\")\n",
        "eco_codes.createOrReplaceTempView(\"eco_codesTemp\")\n",
        "chess_wc_history_game_info.createOrReplaceTempView(\"chess_wc_history_game_infoTemp\")\n",
        "\n",
        "# ----Creating the table from the temp view so that the tables can be accessible globally(accessed across different Spark sessions) #\n",
        "\n",
        "query_main_Event  = \"\"\"Select * from chess_wc_history_game_infoTemp where\n",
        "                        event not like '%KO%' and\n",
        "                        event not like '%k.o.%' \"\"\"\n",
        "\n",
        "\n",
        "# -------------WCh knock out(string with k.o.,KO ) are not included in main event-----------#\n",
        "spark.sql(query_main_Event).createOrReplaceTempView(\"chess_wc_history_game_infoTemp1\")\n",
        "\n",
        "\n",
        "chess_wc_history_movesTempTable = spark.table(\"chess_wc_history_movesTemp\")\n",
        "eco_codesTempTable = spark.table(\"eco_codesTemp\")\n",
        "chess_wc_history_game_infoTempTable = spark.table(\"chess_wc_history_game_infoTemp1\")\n",
        "\n",
        "# Checking the validity of data in table form  using mysql like capabilities in SparkSql\n",
        "#result1 = spark.sql(\"SELECT * FROM chess_wc_history_movesTemp limit 5\")\n",
        "#result1.show()\n",
        "#result2 = spark.sql(\"SELECT * FROM eco_codesTemp\")\n",
        "#result2.show()\n",
        "# result2.printSchema()    # --> to check schema\n",
        "  # result3 = spark.sql(\"SELECT * from chess_wc_history_game_infoTemp limit 5 \")\n",
        "  # result3.show()\n",
        " #spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
        "  # eco_codes.columns    # this is used to check the data frames columns\n",
        "  #chess_wc_history_game_info.columns\n",
        "\n",
        "\n",
        "query1 = \"\"\" WITH CTE_WInner_List AS\n",
        "                (select winner , event,round , tournament_name,date_played,\n",
        "                count(*) over (partition by winner,tournament_name order by date_played) as WinnerCount\n",
        "                from chess_wc_history_game_infoTemp1\n",
        "                where winner not like '%draw%'and\n",
        "                tournament_name like 'WorldChamp%' )\n",
        "                SELECT winner, tournament_name, MAX(WinnerCount) AS Score\n",
        "                FROM CTE_Winner_List\n",
        "                GROUP BY winner ,tournament_name\n",
        "                order BY tournament_name DESC\n",
        "\"\"\"\n",
        "spark.sql(query1).createOrReplaceTempView(\"temp_view1\")\n",
        "\n",
        "final_query1 = \"\"\" with CTE_Final AS (\n",
        "                select winner, tournament_name, Score ,\n",
        "                ROW_NUMBER() OVER (partition by tournament_name order by Score DESC) as Row_num\n",
        "                from temp_view1 )\n",
        "                select winner, tournament_name  --, Score ,Row_num\n",
        "                from CTE_Final\n",
        "                where Row_num = 1\n",
        "                order by tournament_name DESC\n",
        "\"\"\"\n",
        "\n",
        "#  -----------Sollution of 1st Problem ----------------#\n",
        "resultTest1 = spark.sql(final_query1)\n",
        "resultTest1.show()\n",
        "# TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB\n",
        "#resultTest1.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb1\", header=True)\n",
        "# -----------------------2nd Problem mitigation ----------------#\n",
        "spark.sql(final_query1).createOrReplaceTempView(\"Second_problem\")\n",
        "\n",
        "second_problem_query1  = \"\"\"\n",
        "        select winner as Player_name,\n",
        "        count(*) as number_of_wins from Second_problem\n",
        "        group by winner\n",
        "        order by number_of_wins DESC\n",
        "\"\"\"\n",
        "#  -----------Sollution of 2nd Problem ----------------#\n",
        "resultTest2 = spark.sql(second_problem_query1)\n",
        "resultTest2.show()\n",
        "# TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB\n",
        "#resultTest2.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb2\", header=True)\n",
        "# -----------------------3rd Problem mitigation ----------------#\n",
        "\n",
        "third_problem_query0 = \"\"\"\n",
        "                with cte_popular_move as (\n",
        "                select A.eco, A.eco_name, B.game_id,\n",
        "                count(*) over(partition by A.eco, B.game_id  order by A.eco) as no_of_occurances\n",
        "                from eco_codesTemp A left join chess_wc_history_game_infoTemp1 B\n",
        "                on A.eco = B.eco )\n",
        "                select eco, eco_name ,\n",
        "                count(*) over(partition by eco_name order by eco) as occurance\n",
        "                from cte_popular_move\n",
        "                group by eco,eco_name\n",
        "                order by occurance DESC\n",
        "\"\"\"\n",
        "\n",
        "test_res6 = spark.sql(third_problem_query0).createOrReplaceTempView(\"third_query_test0\")\n",
        "#test_res6.show()\n",
        "\n",
        "third_problem_query1 = \"\"\"with cte_test_final as (\n",
        "                        select eco, eco_name,\n",
        "                        occurance as number_of_occurences,\n",
        "                        ROW_NUMBER() over( order by occurance DESC) as MostRow,\n",
        "                        ROW_NUMBER() over( order by occurance ASC) as leastRow\n",
        "                        from third_query_test0 )\n",
        "                        select\n",
        "                        eco,\n",
        "                        eco_name,\n",
        "                        number_of_occurences   --,MostRow, leastRow\n",
        "                        from cte_test_final\n",
        "                        where  MostRow =1 or leastRow = 1\n",
        "                        order by number_of_occurences DESC\n",
        "                        \"\"\"\n",
        "\n",
        "#  -----------Sollution of 3rd Problem ----------------#\n",
        "result_test3 = spark.sql(third_problem_query1)   #.createOrReplaceTempView(\"third_query_test\")\n",
        "result_test3.show()\n",
        "\n",
        "# -----------------------4th Problem mitigation ----------------#\n",
        "\n",
        "fourth_problem_query = \"\"\"\n",
        "                with cte_popular_move_win as (\n",
        "                select A.eco, A.eco_name, B.game_id,B.winner_elo\n",
        "                from eco_codesTemp A left join chess_wc_history_game_infoTemp1 B\n",
        "                on A.eco = B.eco\n",
        "                where B.winner_elo is not null\n",
        "                )\n",
        "                select eco, eco_name ,winner_elo,\n",
        "                count(*) over (partition by eco order by eco) as occurance\n",
        "                from cte_popular_move_win\n",
        "                group by eco,eco_name,winner_elo\n",
        "                order by occurance DESC\n",
        "                --limit 1\n",
        "\"\"\"\n",
        "spark.sql(fourth_problem_query).createOrReplaceTempView(\"fourth_problem_query0\")\n",
        "#r = spark.sql(\"select * from fourth_problem_query0  order by occurance DEsc  limit 10\")\n",
        "#r.show()\n",
        "\n",
        "fourth_problem_query1 = \"\"\"\n",
        "                with CTE_final AS (\n",
        "                select eco, eco_name ,occurance,\n",
        "                ROW_NUMBER() over(order by occurance DESC) as row_num\n",
        "                from fourth_problem_query0 )\n",
        "                select eco, eco_name  --, occurance, row_num\n",
        "                from CTE_final\n",
        "                where  row_num=1\n",
        "                order by occurance DESC \"\"\"\n",
        "\n",
        "#  -----------Sollution of 4th Problem ----------------#\n",
        "result_test4 = spark.sql(fourth_problem_query1 )\n",
        "result_test4.show()\n",
        "\n",
        "# -----------------------5th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "chess_wc_history_game_infoTempTable.createOrReplaceTempView(\"chess_wc_history_game_infoTempTable1\")\n",
        "chess_wc_history_movesTempTable.createOrReplaceTempView(\"chess_wc_history_movesTempTable1\")\n",
        "\n",
        "#test  = spark.sql(\"select game_id, event ,\")\n",
        "\n",
        "# move_no , move_Sequence(even number shoub be there),game_id,event, tournament_name\n",
        "#Longest and shortest game ever played in a world championship in terms of move\n",
        "# Final result will have only two rows\n",
        "fifth_problem_query0 = \"\"\"\n",
        "                        with cte_test_move as (\n",
        "                        select\n",
        "                        A.game_id,B.date_played,\n",
        "                        A.move_no, A.move_no_pair ,\n",
        "                        A.move_Sequence,\n",
        "                        B.event, B.tournament_name,\n",
        "                        B.winner,\n",
        "                        B.loser,\n",
        "                        B.winner_elo,\n",
        "                        B.loser_elo,\n",
        "                        ROW_NUMBER() over(partition by A.game_id, B.date_played order by A.move_Sequence DESC) as longest_move_rank\n",
        "                        --ROW_NUMBER() over(partition by A.game_id, B.date_played order by A.move_Sequence ASC) as shortest_move_rank\n",
        "                        from chess_wc_history_movesTempTable1 A left join chess_wc_history_game_infoTempTable1 B\n",
        "                        on A.game_id =  B.game_id )\n",
        "                        select game_id, date_played,\n",
        "                        --move_no,\n",
        "                        --longest_move_rank as move_rank,\n",
        "                        move_no_pair,\n",
        "                        move_Sequence, event,tournament_name,winner,loser,\n",
        "                        ROW_NUMBER() over(order by move_no_pair DESC) as high_rank,\n",
        "                        --ROW_NUMBER() over(order by move_no_pair ASC) as low_rank,\n",
        "                        winner_elo,loser_elo\n",
        "                        from cte_test_move\n",
        "                        where longest_move_rank = 1 and move_no_pair%2 = 0               --in (1,2,3,4)\n",
        "                         and event is not null\n",
        "                        --group by game_id, date_played, move_no_pair ,move_no\n",
        "                        order by move_no_pair DESC\n",
        "\n",
        "\"\"\"\n",
        "spark.sql(fifth_problem_query0).createOrReplaceTempView(\"fifth_problem_query1\")\n",
        "\n",
        "fifth_problem_query2 = \"\"\"\n",
        "                      WITH CTE_Final AS (\n",
        "                      SELECT\n",
        "                      game_id,\n",
        "                      event,\n",
        "                      tournament_name,\n",
        "                      move_no_pair AS number_of_moves,\n",
        "                      ROW_NUMBER() OVER ( ORDER BY move_no_pair DESC) AS longest_game_played,\n",
        "                      ROW_NUMBER() OVER ( ORDER BY move_no_pair ASC) AS shortest_game_played,\n",
        "                      move_sequence\n",
        "                      FROM fifth_problem_query1\n",
        "                      )\n",
        "                    SELECT\n",
        "                    game_id,\n",
        "                    event,\n",
        "                    tournament_name,\n",
        "                    number_of_moves\n",
        "                    FROM CTE_Final\n",
        "                    WHERE longest_game_played = 1 OR shortest_game_played = 1\n",
        "                    ORDER BY number_of_moves DESC \"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 5th Problem ----------------#\n",
        "result_test5 = spark.sql(fifth_problem_query2)\n",
        "result_test5.show()\n",
        "\n",
        "# -----------------------6th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "sixth_problem_query0 = \"\"\"\n",
        "                        with cte_final_sixth as (\n",
        "                        select\n",
        "                        game_id,\n",
        "                        event,\n",
        "                        tournament_name,\n",
        "                        move_no_pair as number_of_moves,\n",
        "                        ROW_NUMBER()over(order by move_no_pair DESC)as high_rank_draw,\n",
        "                        ROW_NUMBER()over(order by move_no_pair ASC)as low_rank_draw\n",
        "                        from fifth_problem_query1\n",
        "                        where winner like '%draw%' )\n",
        "                        select\n",
        "                        game_id,\n",
        "                        event,\n",
        "                        tournament_name,\n",
        "                        number_of_moves\n",
        "                        from cte_final_sixth\n",
        "                        where high_rank_draw = 1 or low_rank_draw = 1\n",
        "                        order by number_of_moves DESC\"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 6th Problem ----------------#\n",
        "result_test6 = spark.sql(sixth_problem_query0)\n",
        "result_test6.show()\n",
        "\n",
        "# -----------------------7th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "seventh_problem_query0 = \"\"\"\n",
        "                        with cte_Final_playerRanks as (\n",
        "                        select\n",
        "                        winner as player_name ,\n",
        "                        winner_elo as elo,\n",
        "                        ROW_NUMBER() over ( order by winner_elo DESC) as ranking_high,\n",
        "                        ROW_NUMBER() over ( order by winner_elo ASC) as ranking_low\n",
        "                        from chess_wc_history_game_infoTempTable1\n",
        "                        where winner_elo is not null and loser_elo is not null )\n",
        "                        select player_name, elo\n",
        "                        from cte_Final_playerRanks\n",
        "                        where ranking_high =1  or ranking_low = 1\n",
        "                        order by elo DESC\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 7th Problem ----------------#\n",
        "result_test7 = spark.sql(seventh_problem_query0)\n",
        "result_test7.show()\n",
        "\n",
        "\n",
        "# -----------------------8th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "eighth_problem_query0 = \"\"\"\n",
        "                with cte_final_mostlossPlayer as (\n",
        "                select\n",
        "                game_id,\n",
        "                loser as player_name,\n",
        "                event,\n",
        "                count(*) over(partition by loser order by event) as loss_countofPlayer\n",
        "                from  chess_wc_history_game_infoTempTable1 )\n",
        "                select distinct\n",
        "                player_name ,\n",
        "                loss_countofPlayer\n",
        "                --ROW_NUMBER() over( partition by player_name, loss_countofPlayer  order by loss_countofPlayer DESC) as loss_ranking\n",
        "                from cte_final_mostlossPlayer\n",
        "                where player_name not like '%draw%'\n",
        "                order by loss_countofPlayer DESC\n",
        " \"\"\"\n",
        "spark.sql(eighth_problem_query0).createOrReplaceTempView(\"eighth_problem_test1\")\n",
        "\n",
        "\n",
        "# this below query will give unique records of the highest loss the person has taken in overall\n",
        "# used the offset to skip 1st 2 rows of sorted table and getting the 3rd Last Player with most Loss\n",
        "eighth_problem_query1 = \"\"\"\n",
        "                        with cte_intermediate_lossdetails as (\n",
        "                        select\n",
        "                        player_name,\n",
        "                        loss_countofPlayer,\n",
        "                        ROW_NUMBER() over(partition by player_name order by loss_countofPlayer DESC) as row_num1\n",
        "                        from eighth_problem_test1 )\n",
        "                        select\n",
        "                        player_name,\n",
        "                        loss_countofPlayer\n",
        "                        from cte_intermediate_lossdetails\n",
        "                        where row_num1 = 1\n",
        "                        group by player_name,loss_countofPlayer\n",
        "                        order by loss_countofPlayer DESC\n",
        "                        --limit 1 offset 2\n",
        "\"\"\"\n",
        "spark.sql(eighth_problem_query1).createOrReplaceTempView(\"eighth_problem_test2\")\n",
        "\n",
        "eighth_problem_query2 =\"\"\"\n",
        "                        with cte_Final as (\n",
        "                        select\n",
        "                        player_name  ,\n",
        "                        loss_countofPlayer ,\n",
        "                        RANK() over( order by loss_countofPlayer DESC) as rank\n",
        "                        from eighth_problem_test2 )\n",
        "                        select player_name\n",
        "                        from cte_Final\n",
        "                        where rank = 3\"\"\"\n",
        "\n",
        "#  -----------Sollution of 8th Problem ----------------#\n",
        "result_test8 = spark.sql(eighth_problem_query2)\n",
        "result_test8.show()\n",
        "\n",
        "# -----------------------9th Problem mitigation ----------------#\n",
        "# How many times players with low rating won matches with their total win Count.\n",
        "# Result attributes: player_name, win_count\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "#Required fields - game_id , event, tournament_name,winner,winner_elo,loser,loser_elo, date_played\n",
        "\n",
        "ninth_problem_query = \"\"\"\n",
        "                        with cte_lowRankWinner as (\n",
        "                        select\n",
        "                        --A.game_id,\n",
        "                        --A.date_played,\n",
        "                        --A.event,\n",
        "                        --A.tournament_name,\n",
        "                        A.winner,A.winner_elo,\n",
        "                        count(*) over(partition by A.winner order by A.winner) as countOfLowRankWinners,\n",
        "                        Row_Number() over(partition by A.winner order by A.winner) as row_num,\n",
        "                        B.loser,B.loser_elo\n",
        "                        from chess_wc_history_game_infoTempTable1 A left join chess_wc_history_game_infoTempTable1 B\n",
        "                        on A.game_id = B.game_id\n",
        "                        where A.winner not like '%draw%'and A.winner_elo is not null\n",
        "                        and B.loser_elo > A.winner_elo\n",
        "                        group by A.winner,A.winner_elo,B.loser,B.loser_elo )\n",
        "                        select\n",
        "                        winner as player_name,\n",
        "                        countOfLowRankWinners as win_count\n",
        "                        from cte_lowRankWinner\n",
        "                        where row_num = 1\n",
        "                        order by countOfLowRankWinners DESC\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 9th Problem ----------------#\n",
        "resultTest9 = spark.sql(ninth_problem_query)\n",
        "resultTest9.show()\n",
        "#---------- TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB ------------#\n",
        "#resultTest9.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb9\", header=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------10th Problem mitigation ----------------#\n",
        "# Move Sequence for Each Player in a Match.\n",
        "# Result attributes: game_id, player_name, move_sequence, move_count\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "# REquired fields : game_id, move_no, move_no_pair, player , move , move_sequence\n",
        "\n",
        "tenth_problem_query = \"\"\"\n",
        "                        with cte_movSequence as (\n",
        "                        select\n",
        "                        game_id, move_no,\n",
        "                        move_no_pair, player , notation,\n",
        "                        move , move_sequence,\n",
        "                        ROW_NUMBER()over(partition by game_id,player order by move_no_pair DESC) as movRowSeq\n",
        "                        from chess_wc_history_movesTemp )\n",
        "                        select\n",
        "                        game_id,\n",
        "                        player as player_name ,\n",
        "                        move_sequence,\n",
        "                        move_no as move_count\n",
        "                        --(LENGTH(move_sequence) - LENGTH(REPLACE(move_sequence, '|', '')) + 1) AS move_count,\n",
        "                        --movRowSeq\n",
        "                        from cte_movSequence\n",
        "                        where movRowSeq = 1\n",
        "                        order by  move_no DESC \"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 10th Problem ----------------#\n",
        "result_test10 = spark.sql(tenth_problem_query)\n",
        "result_test10.show()\n",
        "\n",
        "\n",
        "# -----------------------11th Problem mitigation ----------------#\n",
        "\n",
        "#Total Number of games where losing player has more Captured score than Winning player.\n",
        "#Hint: Captured score is cumulative, i.e., for 3rd capture it will have score for 1, 2, and 3rd.\n",
        "#Result attributes: total_number_of_games Final result will have only one row\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "\n",
        "\n",
        "# REquired fields :\n",
        "# from chess_wc_history_movesTemp - captured_score_for_white,captured_score_for_black , game_id,\n",
        "# from chess_wc_history_game_infoTempTable1 : winner, winner_elo, loser,loser_elo ,game_id\n",
        "\n",
        "eleventh_problem_query0 = \"\"\"\n",
        "                        select\n",
        "                        distinct\n",
        "                        game_id,\n",
        "                        sum(captured_score_for_white) over(partition by game_id order by game_id) as CumilativeOfWhite,\n",
        "                        sum(captured_score_for_black) over(partition by game_id order by game_id) as CumilativeOfBlack\n",
        "                        from chess_wc_history_movesTemp\n",
        "                        where captured_score_for_white != 0 and captured_score_for_black !=0\n",
        "\n",
        "\"\"\"\n",
        "spark.sql(eleventh_problem_query0).createOrReplaceTempView(\"eleventh_query1\")\n",
        "\n",
        "eleventh_problem_query1 = \"\"\"\n",
        "                        select\n",
        "                        A.game_id,\n",
        "                        A.CumilativeOfWhite,\n",
        "                        A.CumilativeOfBlack,\n",
        "                        B.white, B.black,\n",
        "                        B.winner,B.loser\n",
        "                        from  eleventh_query1 A left join  chess_wc_history_game_infoTempTable1 B\n",
        "                        on A.game_id = B.game_id\n",
        "                        where B.winner not like '%draw%' and B.winner_elo is not null\n",
        "\n",
        "\"\"\"\n",
        "spark.sql(eleventh_problem_query1).createOrReplaceTempView(\"eleventh_query2\")\n",
        "eleventh_problem_query2 = \"\"\"\n",
        "                        with cte_finalGameScore as (\n",
        "                        select\n",
        "                        game_id ,\n",
        "                        case\n",
        "                        when winner == black then CumilativeOfBlack\n",
        "                                else CumilativeOfWhite\n",
        "                        end as winnerScore,\n",
        "                        case\n",
        "                        when loser == black then CumilativeOfBlack\n",
        "                                else CumilativeOfWhite\n",
        "                        end as loserScore,\n",
        "                        CumilativeOfBlack,\n",
        "                        CumilativeOfWhite,\n",
        "                        white,black,\n",
        "                        winner, loser\n",
        "                        from eleventh_query2 )\n",
        "                        select\n",
        "                        count(*) as total_number_of_games\n",
        "                        from cte_finalGameScore\n",
        "                        where loserScore > winnerScore\n",
        "\n",
        "\"\"\"\n",
        "#  -----------Sollution of 11th Problem ----------------#\n",
        "result_test11 = spark.sql(eleventh_problem_query2)\n",
        "result_test11.show()\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------12th Problem mitigation ----------------#\n",
        "\n",
        "#List All Perfect Tournament with Winner Name.\n",
        "#Chess Funda: Perfect Tournament means a player has won all the matches excluding draw matches. e.g Player A has won 5 matches out of 7\n",
        "#Matches in tournament where 2 matches are draw and player B has won 0 matches)\n",
        "#Result attributes: winner_name, tournament_name\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "# to find the perfect tournament where the winner not would have came in loser list even at once\n",
        "# here we can use the 1st problems solutions answer to answer this question\n",
        "spark.sql(final_query1).createOrReplaceTempView(\"WinnerOfAllTournaments\")\n",
        "\n",
        "spark.sql(\"select tournament_name,loser from chess_wc_history_game_infoTempTable1  where tournament_name like 'WorldChamp%' group by tournament_name,loser order by tournament_name\").createOrReplaceTempView(\"LoserOfTournaments\")\n",
        "\n",
        "twelth_problem_query0 = \"\"\"\n",
        "                with CTE_PerfectMatchChecking as (\n",
        "                select\n",
        "                A.winner,\n",
        "                A.tournament_name,\n",
        "                B.loser,\n",
        "                (case\n",
        "                when (A.winner = B.loser and A.tournament_name = B.tournament_name)\n",
        "                then 1\n",
        "                else 0\n",
        "                end )as ValueWinLose\n",
        "                from WinnerOfAllTournaments A left join  LoserOfTournaments B\n",
        "                on A.tournament_name = B.tournament_name\n",
        "                where  --A.tournament_name like '%WorldChamp1889%' and\n",
        "                 loser not like '%draw%' )\n",
        "                select  distinct\n",
        "                winner,\n",
        "                tournament_name,\n",
        "                sum(ValueWinLose)over(partition by tournament_name order by tournament_name) as WinnerLosingValue\n",
        "                from  CTE_PerfectMatchChecking\n",
        "                order by tournament_name DESC \"\"\"\n",
        "\n",
        "spark.sql(twelth_problem_query0).createOrReplaceTempView(\"twelth_query1\")\n",
        "#  -----------Sollution of 12th Problem ----------------#\n",
        "\n",
        "result_test12 = spark.sql(\"select winner,tournament_name as Perferct_tournament_name from twelth_query1 where WinnerLosingValue = 0 \")\n",
        "result_test12.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------13th Problem mitigation ----------------#\n",
        "# Player with highest winning ratio.\n",
        "# Hint: Winning ratio: (Number of rounds won)/(Number of rounds played)\n",
        "# Result attributes: player_name\n",
        "# Final result will have only one row\n",
        "\n",
        "\n",
        "# chess_wc_history_movesTempTable.show()\n",
        "# eco_codesTempTable.show()\n",
        "# chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "\n",
        "# REquired fields :\n",
        "\n",
        "thirteen_problem_query0 = \"\"\"\n",
        "       with CTE_FINAL as (\n",
        "       select\n",
        "       white, black,\n",
        "       winner,\n",
        "       count(*) over(partition by tournament_name, winner order by tournament_name) as winCount ,\n",
        "       max(round) over(partition by  tournament_name order by tournament_name) as NumRoundPlayed,\n",
        "       tournament_name,\n",
        "       round,event\n",
        "       from chess_wc_history_game_infoTemp1\n",
        "       --where winner not like '%draw%'\n",
        "       order by tournament_name,round DESC )\n",
        "       select\n",
        "       Distinct\n",
        "       winner as player_name,\n",
        "       round((winCount/NumRoundPlayed),2) as winningRatio\n",
        "       from\n",
        "       CTE_FINAL\n",
        "       where winner not like '%draw%'\n",
        "       order by winningRatio DESC\n",
        "       limit 1\n",
        "       \"\"\"\n",
        "\n",
        "#  -----------Sollution of 13th Problem ---------------- #\n",
        "\n",
        "result_test13 = spark.sql(thirteen_problem_query0)\n",
        "result_test13.show()\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------14th Problem mitigation ----------------#\n",
        "# Player who had given checkmate with Pawn.\n",
        "# Note: Consider all events for this query\n",
        "# Result attributes: player_name\n",
        "# Final result will have only one row\n",
        "# P for pawn\n",
        "\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "fourteenth_problem_query0 = \"\"\"\n",
        "                        with CTE_CheckmateWithPawn as (\n",
        "                        select\n",
        "                        A.game_id ,\n",
        "                        B.winner,\n",
        "                        B.loser,\n",
        "                        B.winner_elo,\n",
        "                        A.move, A.player,\n",
        "                        A.white_pawn_count,\n",
        "                        A.black_pawn_count,\n",
        "                        A.piece,\n",
        "                        A.is_check_mate\n",
        "                        from chess_wc_history_movesTemp  A left join  chess_wc_history_game_infoTemp B\n",
        "                        on A.game_id = B.game_id\n",
        "                        where  A.is_check_mate != 0 )\n",
        "                        select\n",
        "                        winner as player_name\n",
        "                        from CTE_CheckmateWithPawn\n",
        "                        where piece like '%P%' \"\"\"\n",
        "\n",
        "#  -----------Sollution of 14th Problem ----------------#\n",
        "result_test14 = spark.sql(fourteenth_problem_query0)\n",
        "result_test14.show()\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------15th Problem mitigation ----------------#\n",
        "# List games where player has won game without queen.\n",
        "# Result attributes: game_id, event, player_name\n",
        "\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "fifteenth_problem_query0 = \"\"\"\n",
        "                        with cte_testNoQueen as (\n",
        "                        select\n",
        "                        game_id ,\n",
        "                        player,\n",
        "                        move_no,\n",
        "                        move_no_pair,\n",
        "                        case when piece like '%Q%' then 1 else 0\n",
        "                        end as QueenUsage\n",
        "                        from chess_wc_history_movesTemp  )\n",
        "                        --group by game_id, player\n",
        "                        select  distinct\n",
        "                        game_id ,\n",
        "                        player,\n",
        "                        sum(QueenUsage) over (partition by game_id, player order by game_id) as QueenUsageVal\n",
        "                        from cte_testNoQueen\n",
        "\"\"\"\n",
        "spark.sql(fifteenth_problem_query0).createOrReplaceTempView(\"fifteenth_query1\")\n",
        "\n",
        "fifteenth_problem_query1 = \"\"\"\n",
        "                with CTE_winWithoutQueen as (\n",
        "                SELECT\n",
        "                A.game_id,\n",
        "                A.player,\n",
        "                B.winner as Winner_player_name,\n",
        "                B.event,\n",
        "                A.QueenUsageVal\n",
        "                from\n",
        "                fifteenth_query1 A left join  chess_wc_history_game_infoTemp B\n",
        "                on A.game_id = B.game_id and A.player = B.winner\n",
        "                where  A.QueenUsageVal = 0\n",
        "                and B.winner not like '%draw%' )\n",
        "                select\n",
        "                game_id, event,\n",
        "                Winner_player_name as player_name\n",
        "                from CTE_winWithoutQueen\n",
        "                order by event DESC \"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 15th Problem ----------------#\n",
        "result_test15 = spark.sql(fifteenth_problem_query1)\n",
        "result_test15.show()\n",
        "#result_test15.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb15\", header=True)\n",
        "\n",
        "# list of the sparkDataframes(all that are final results )so that\n",
        "# we can use this to pass it function and convert that in pandas DF\n",
        "\n",
        "\n",
        "spark_df_list = [\n",
        "resultTest1,\n",
        "resultTest2,\n",
        "result_test3,\n",
        "result_test4,\n",
        "result_test5,\n",
        "result_test6,\n",
        "result_test7,\n",
        "result_test8,\n",
        "resultTest9,\n",
        "result_test10,\n",
        "result_test11,\n",
        "result_test12,\n",
        "result_test13,\n",
        "result_test14,\n",
        "result_test15]\n",
        "\n",
        "\n",
        "# Google Drive path\n",
        "drive_path = 'DE_SOLUTION_Gajendra_Ahirkar/results/'\n",
        "\n",
        "\n",
        "# Using the function to save dataframes to given path in csv format\n",
        "spark_dataframes_to_csv(spark_df_list,drive_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ-Zo_yS2Zuu",
        "outputId": "b45639dd-a30e-43bc-f75a-8a0ebe9d5467"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|              winner|tournament_name|\n",
            "+--------------------+---------------+\n",
            "|           Carlsen,M| WorldChamp2021|\n",
            "|     Carlsen, Magnus| WorldChamp2016|\n",
            "|     Carlsen, Magnus| WorldChamp2014|\n",
            "|     Carlsen, Magnus| WorldChamp2013|\n",
            "|           Gelfand,B| WorldChamp2012|\n",
            "|             Anand,V| WorldChamp2010|\n",
            "|             Anand,V| WorldChamp2008|\n",
            "|             Anand,V| WorldChamp2007|\n",
            "|           Kramnik,V| WorldChamp2006|\n",
            "|              Leko,P| WorldChamp2004|\n",
            "|           Kramnik,V| WorldChamp2000|\n",
            "|      Kasparov, Gary| WorldChamp1990|\n",
            "|      Kasparov, Gary| WorldChamp1987|\n",
            "|      Kasparov, Gary| WorldChamp1986|\n",
            "|      Kasparov, Gary| WorldChamp1985|\n",
            "|     Karpov, Anatoly| WorldChamp1984|\n",
            "|     Karpov, Anatoly| WorldChamp1981|\n",
            "|     Karpov, Anatoly| WorldChamp1978|\n",
            "|Fischer, Robert J...| WorldChamp1972|\n",
            "|    Spassky, Boris V| WorldChamp1969|\n",
            "+--------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+--------------+\n",
            "|         Player_name|number_of_wins|\n",
            "+--------------------+--------------+\n",
            "|     Lasker, Emanuel|             6|\n",
            "|  Botvinnik, Mikhail|             5|\n",
            "|      Kasparov, Gary|             4|\n",
            "|   Steinitz, William|             4|\n",
            "| Alekhine, Alexander|             4|\n",
            "|     Carlsen, Magnus|             3|\n",
            "|     Karpov, Anatoly|             3|\n",
            "|             Anand,V|             3|\n",
            "| Petrosian, Tigran V|             2|\n",
            "|           Kramnik,V|             2|\n",
            "|           Carlsen,M|             1|\n",
            "|              Leko,P|             1|\n",
            "|    Spassky, Boris V|             1|\n",
            "|    Schlechter, Carl|             1|\n",
            "|           Euwe, Max|             1|\n",
            "|Fischer, Robert J...|             1|\n",
            "|    Smyslov, Vassily|             1|\n",
            "|         Tal, Mihail|             1|\n",
            "|           Gelfand,B|             1|\n",
            "|Capablanca, Jose ...|             1|\n",
            "+--------------------+--------------+\n",
            "\n",
            "+---+-----------------+--------------------+\n",
            "|eco|         eco_name|number_of_occurences|\n",
            "+---+-----------------+--------------------+\n",
            "|B89|         Sicilian|                  15|\n",
            "|D97|Grunfeld, Russian|                   1|\n",
            "+---+-----------------+--------------------+\n",
            "\n",
            "+---+--------------+\n",
            "|eco|      eco_name|\n",
            "+---+--------------+\n",
            "|C42|Petrov Defense|\n",
            "+---+--------------+\n",
            "\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|             game_id|               event|tournament_name|number_of_moves|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|58e83255-93bb-4d5...|            WCh 2021| WorldChamp2021|            136|\n",
            "|7e3065e9-94cc-4ee...|World Championshi...| WorldChamp1963|             10|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|             game_id|               event|tournament_name|number_of_moves|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|bf66c982-f6c5-4e7...|World Championshi...| WorldChamp1978|            124|\n",
            "|7e3065e9-94cc-4ee...|World Championshi...| WorldChamp1963|             10|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "\n",
            "+---------------+----+\n",
            "|    player_name| elo|\n",
            "+---------------+----+\n",
            "|Carlsen, Magnus|2870|\n",
            "|  Timman, Jan H|2620|\n",
            "+---------------+----+\n",
            "\n",
            "+---------------+\n",
            "|    player_name|\n",
            "+---------------+\n",
            "|Karpov, Anatoly|\n",
            "+---------------+\n",
            "\n",
            "+------------------+---------+\n",
            "|       player_name|win_count|\n",
            "+------------------+---------+\n",
            "|   Karpov, Anatoly|        4|\n",
            "|      Morozevich,A|        3|\n",
            "|         Gelfand,B|        3|\n",
            "|         Kramnik,V|        3|\n",
            "|Kortschnoj, Viktor|        2|\n",
            "|            Leko,P|        2|\n",
            "|Anand, Viswanathan|        2|\n",
            "|        Grischuk,A|        2|\n",
            "|    Kasimdzhanov,R|        2|\n",
            "|    Short, Nigel D|        1|\n",
            "|     Timman, Jan H|        1|\n",
            "|  Spassky, Boris V|        1|\n",
            "|  Karjakin, Sergey|        1|\n",
            "|      Kamsky, Gata|        1|\n",
            "|    Kasparov, Gary|        1|\n",
            "|         Svidler,P|        1|\n",
            "|           Anand,V|        1|\n",
            "|         Aronian,L|        1|\n",
            "+------------------+---------+\n",
            "\n",
            "+--------------------+------------------+--------------------+----------+\n",
            "|             game_id|       player_name|       move_sequence|move_count|\n",
            "+--------------------+------------------+--------------------+----------+\n",
            "|4424a0a4-3732-407...|         Chernin,A|d4|d5|c4|c6|Nc3|N...|       291|\n",
            "|4424a0a4-3732-407...|       Utnasunov,A|d4|d5|c4|c6|Nc3|N...|       290|\n",
            "|58e83255-93bb-4d5...|         Carlsen,M|d4|Nf6|Nf3|d5|g3|...|       271|\n",
            "|58e83255-93bb-4d5...|  Nepomniachtchi,I|d4|Nf6|Nf3|d5|g3|...|       270|\n",
            "|88f34084-e4df-490...|         Svidler,P|Nf3|Nf6|c4|e6|d4|...|       258|\n",
            "|88f34084-e4df-490...|         Gelfand,B|Nf3|Nf6|c4|e6|d4|...|       257|\n",
            "|bf66c982-f6c5-4e7...|Kortschnoj, Viktor|c4|Nf6|d4|e6|Nc3|...|       247|\n",
            "|bf66c982-f6c5-4e7...|   Karpov, Anatoly|c4|Nf6|d4|e6|Nc3|...|       246|\n",
            "|c2ad1d49-8a47-428...|       Krasenkow,M|e4|c5|Nf3|Nc6|d4|...|       244|\n",
            "|c2ad1d49-8a47-428...|           Short,N|e4|c5|Nf3|Nc6|d4|...|       243|\n",
            "|ed4f54c2-4e7f-443...|   Carlsen, Magnus|e4|e5|Nf3|Nc6|Bb5...|       243|\n",
            "|ed4f54c2-4e7f-443...|Anand, Viswanathan|e4|e5|Nf3|Nc6|Bb5...|       242|\n",
            "|c027c41f-a2e6-4a5...|Botvinnik, Mikhail|e4|c6|d4|d5|e5|Bf...|       242|\n",
            "|c027c41f-a2e6-4a5...|       Tal, Mihail|e4|c6|d4|d5|e5|Bf...|       241|\n",
            "|1f094f29-ffeb-434...|   Lasker, Emanuel|e4|e5|Nf3|Nc6|Bb5...|       238|\n",
            "|1f094f29-ffeb-434...|Tarrasch, Siegbert|e4|e5|Nf3|Nc6|Bb5...|       237|\n",
            "|180c123b-a5e0-41f...|  Miles, Anthony J|d4|e6|Nf3|c5|c4|c...|       236|\n",
            "|180c123b-a5e0-41f...| Krasenkow, Michal|d4|e6|Nf3|c5|c4|c...|       235|\n",
            "|99d39a93-427e-4d1...|  Caruana, Fabiano|e4|c5|Nf3|Nc6|Bb5...|       229|\n",
            "|99d39a93-427e-4d1...|   Carlsen, Magnus|e4|c5|Nf3|Nc6|Bb5...|       228|\n",
            "+--------------------+------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---------------------+\n",
            "|total_number_of_games|\n",
            "+---------------------+\n",
            "|                   50|\n",
            "+---------------------+\n",
            "\n",
            "+--------------------+------------------------+\n",
            "|              winner|Perferct_tournament_name|\n",
            "+--------------------+------------------------+\n",
            "|           Carlsen,M|          WorldChamp2021|\n",
            "|     Carlsen, Magnus|          WorldChamp2013|\n",
            "|             Anand,V|          WorldChamp2007|\n",
            "|           Kramnik,V|          WorldChamp2000|\n",
            "|Capablanca, Jose ...|          WorldChamp1921|\n",
            "|     Lasker, Emanuel|         WorldChamp1910b|\n",
            "|     Lasker, Emanuel|          WorldChamp1907|\n",
            "+--------------------+------------------------+\n",
            "\n",
            "+---------------+------------+\n",
            "|    player_name|winningRatio|\n",
            "+---------------+------------+\n",
            "|Lasker, Emanuel|        0.73|\n",
            "+---------------+------------+\n",
            "\n",
            "+--------------+\n",
            "|   player_name|\n",
            "+--------------+\n",
            "|Andersson, Ulf|\n",
            "+--------------+\n",
            "\n",
            "+--------------------+--------------------+-------------------+\n",
            "|             game_id|               event|        player_name|\n",
            "+--------------------+--------------------+-------------------+\n",
            "|672aff57-531d-4c4...|World Championshi...|  Steinitz, William|\n",
            "|85487c3b-8f21-4a1...|World Championshi...|    Lasker, Emanuel|\n",
            "|9603beef-7a9a-49a...|World Championshi...|    Lasker, Emanuel|\n",
            "|991fb6b1-04ed-49b...|World Championshi...|    Lasker, Emanuel|\n",
            "|1fdb22ea-3861-483...|World Championshi...|    Karpov, Anatoly|\n",
            "|4ec12417-3e9f-46a...|World Championshi...|    Karpov, Anatoly|\n",
            "|a1460493-82a7-439...|World Championshi...|   Spassky, Boris V|\n",
            "|5fbc8d4f-b8af-4ac...|World Championshi...|Petrosian, Tigran V|\n",
            "|a744139e-aff8-4d3...|World Championshi...|        Tal, Mihail|\n",
            "|9a769e81-af58-4a2...|World Championshi...| Botvinnik, Mikhail|\n",
            "|ef56e988-f8cf-4d7...|World Championshi...| Botvinnik, Mikhail|\n",
            "|7f411b65-e2dd-477...|World Championshi...|   Smyslov, Vassily|\n",
            "|ae5c3771-1daf-4e6...|World Championshi...|    Lasker, Emanuel|\n",
            "|aa9020da-7a79-48b...|            WCh-FIDE|             Leko,P|\n",
            "|7ea5cbe6-7f26-42b...|            WCh-FIDE|          Svidler,P|\n",
            "|816db6b8-260e-488...|            WCh-FIDE|          Topalov,V|\n",
            "|696d8975-7f17-48b...|                 WCh|          Aronian,L|\n",
            "|c17422ff-34bd-4b3...|FIDE-Wch k.o. g/2...|  Rublevsky, Sergei|\n",
            "|a8c3d626-b990-484...|FIDE-Wch k.o. g/2...|     Almasi, Zoltan|\n",
            "|e937b54e-7950-4f0...|       FIDE-Wch k.o.|    Milos, Gilberto|\n",
            "+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "DataFrame 1 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df1.csv\n",
            "DataFrame 2 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df2.csv\n",
            "DataFrame 3 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df3.csv\n",
            "DataFrame 4 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df4.csv\n",
            "DataFrame 5 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df5.csv\n",
            "DataFrame 6 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df6.csv\n",
            "DataFrame 7 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df7.csv\n",
            "DataFrame 8 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df8.csv\n",
            "DataFrame 9 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df9.csv\n",
            "DataFrame 10 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df10.csv\n",
            "DataFrame 11 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df11.csv\n",
            "DataFrame 12 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df12.csv\n",
            "DataFrame 13 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df13.csv\n",
            "DataFrame 14 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df14.csv\n",
            "DataFrame 15 saved as /content/gdrive/MyDrive/DE_SOLUTION_Gajendra_Ahirkar/results//df15.csv\n"
          ]
        }
      ]
    }
  ]
}