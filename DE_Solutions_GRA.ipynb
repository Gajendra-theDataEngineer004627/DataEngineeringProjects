{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpaPVNftnFzApW9eYbnkHn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gajendra-theDataEngineer004627/Test/blob/ChessChampionshipProject/DE_Solutions_GRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uWVNb5Ai3V3"
      },
      "outputs": [],
      "source": [
        "!apt-get update -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "af-JE2bHjxxM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "Ne1MHHMdkO7x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "XgZd6iOskebJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "jnjdlT4CkjII"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "ACgBCh7PktWA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = (SparkSession\n",
        " .builder\n",
        " .appName(\"<app_name>\")\n",
        " .getOrCreate())\n"
      ],
      "metadata": {
        "id": "ob8j-c-ckx4I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to doanload data files from the google drive\n",
        "import gdown\n",
        "def downloadfiles_fromFolder() :\n",
        "    url = \"https://drive.google.com/drive/folders/1QgWPHV_l25Ui9L7et8mkZohAOG59UTkQ\"   # can also be used input()\n",
        "    if url.split(\"/\")[-1]== \"?usp=sharing\":\n",
        "       url = url.replace(\"?usp=sharing\",\"\")\n",
        "    gdown.download_folder(url, output=\"/content\")\n",
        "\n",
        "downloadfiles_fromFolder()"
      ],
      "metadata": {
        "id": "egBrBPncpxL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the datasets for each data files and understanding the data\n",
        "\n",
        "chess_wc_history_game_info = spark.read.load(\"/content/chess_wc_history_game_info.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "chess_wc_history_moves = spark.read.load(\"/content/chess_wc_history_moves.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "eco_codes = spark.read.load(\"/content/eco_codes.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n"
      ],
      "metadata": {
        "id": "ciwD1tV_w6G4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the top 10 records are properly loaded or not\n",
        "# print(chess_wc_history_moves.head())\n",
        "# print(eco_codes.head())\n",
        "# print(chess_wc_history_game_info.head())"
      ],
      "metadata": {
        "id": "44qmU1Vo0eSY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating temporary view for data manupulations\n",
        "chess_wc_history_moves.createOrReplaceTempView(\"chess_wc_history_movesTemp\")\n",
        "eco_codes.createOrReplaceTempView(\"eco_codesTemp\")\n",
        "chess_wc_history_game_info.createOrReplaceTempView(\"chess_wc_history_game_infoTemp\")\n",
        "\n",
        "# ----Creating the table from the temp view so that the tables can be accessible globally(accessed across different Spark sessions) #\n",
        "\n",
        "query_main_Event  = \"\"\"Select * from chess_wc_history_game_infoTemp where\n",
        "                        event not like '%KO%' and\n",
        "                        event not like '%k.o.%' \"\"\"\n",
        "\n",
        "\n",
        "# -------------WCh knock out(string with k.o.,KO ) are not included in main event-----------#\n",
        "spark.sql(query_main_Event).createOrReplaceTempView(\"chess_wc_history_game_infoTemp1\")\n",
        "\n",
        "\n",
        "chess_wc_history_movesTempTable = spark.table(\"chess_wc_history_movesTemp\")\n",
        "eco_codesTempTable = spark.table(\"eco_codesTemp\")\n",
        "chess_wc_history_game_infoTempTable = spark.table(\"chess_wc_history_game_infoTemp1\")\n",
        "\n",
        "# Checking the validity of data in table form  using mysql like capabilities in SparkSql\n",
        "#result1 = spark.sql(\"SELECT * FROM chess_wc_history_movesTemp limit 5\")\n",
        "#result1.show()\n",
        "#result2 = spark.sql(\"SELECT * FROM eco_codesTemp\")\n",
        "#result2.show()\n",
        "# result2.printSchema()    # --> to check schema\n",
        "  # result3 = spark.sql(\"SELECT * from chess_wc_history_game_infoTemp limit 5 \")\n",
        "  # result3.show()\n",
        " #spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
        "  # eco_codes.columns    # this is used to check the data frames columns\n",
        "  #chess_wc_history_game_info.columns\n",
        "\n",
        "\n",
        "query1 = \"\"\" WITH CTE_WInner_List AS\n",
        "                (select winner , event,round , tournament_name,date_played,\n",
        "                count(*) over (partition by winner,tournament_name order by date_played) as WinnerCount\n",
        "                from chess_wc_history_game_infoTemp1\n",
        "                where winner not like '%draw%'and\n",
        "                tournament_name like 'WorldChamp%' )\n",
        "                SELECT winner, tournament_name, MAX(WinnerCount) AS Score\n",
        "                FROM CTE_Winner_List\n",
        "                GROUP BY winner ,tournament_name\n",
        "                order BY tournament_name DESC\n",
        "\"\"\"\n",
        "spark.sql(query1).createOrReplaceTempView(\"temp_view1\")\n",
        "\n",
        "final_query1 = \"\"\" with CTE_Final AS (\n",
        "                select winner, tournament_name, Score ,\n",
        "                ROW_NUMBER() OVER (partition by tournament_name order by Score DESC) as Row_num\n",
        "                from temp_view1 )\n",
        "                select winner, tournament_name  --, Score\n",
        "                from CTE_Final\n",
        "                where Row_num = 1\n",
        "                order by tournament_name DESC\n",
        "\"\"\"\n",
        "\n",
        "#  -----------Sollution of 1st Problem ----------------#\n",
        "resultTest1 = spark.sql(final_query1)\n",
        "resultTest1.show()\n",
        "# TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB\n",
        "#resultTest1.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb1\", header=True)\n",
        "# -----------------------2nd Problem mitigation ----------------#\n",
        "spark.sql(final_query1).createOrReplaceTempView(\"Second_problem\")\n",
        "\n",
        "second_problem_query1  = \"\"\"\n",
        "        select winner as Player_name,\n",
        "        count(*) as number_of_wins from Second_problem\n",
        "        group by winner\n",
        "        order by number_of_wins DESC\n",
        "\"\"\"\n",
        "#  -----------Sollution of 2nd Problem ----------------#\n",
        "resultTest2 = spark.sql(second_problem_query1)\n",
        "resultTest2.show()\n",
        "# TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB\n",
        "#resultTest2.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb2\", header=True)\n",
        "# -----------------------3rd Problem mitigation ----------------#\n",
        "\n",
        "third_problem_query0 = \"\"\"\n",
        "                with cte_popular_move as (\n",
        "                select A.eco, A.eco_name, B.game_id,\n",
        "                count(*) over(partition by A.eco, B.game_id  order by A.eco) as no_of_occurances\n",
        "                from eco_codesTemp A left join chess_wc_history_game_infoTemp1 B\n",
        "                on A.eco = B.eco )\n",
        "                select eco, eco_name ,\n",
        "                count(*) over(partition by eco_name order by eco) as occurance\n",
        "                from cte_popular_move\n",
        "                group by eco,eco_name\n",
        "                order by occurance DESC\n",
        "\"\"\"\n",
        "\n",
        "test_res6 = spark.sql(third_problem_query0).createOrReplaceTempView(\"third_query_test0\")\n",
        "#test_res6.show()\n",
        "\n",
        "third_problem_query1 = \"\"\"with cte_test_final as (\n",
        "                        select eco, eco_name,\n",
        "                        occurance as number_of_occurences,\n",
        "                        ROW_NUMBER() over( order by occurance DESC) as MostRow,\n",
        "                        ROW_NUMBER() over( order by occurance ASC) as leastRow\n",
        "                        from third_query_test0 )\n",
        "                        select\n",
        "                        eco,\n",
        "                        eco_name,\n",
        "                        number_of_occurences   --,MostRow, leastRow\n",
        "                        from cte_test_final\n",
        "                        where  MostRow =1 or leastRow = 1\n",
        "                        order by number_of_occurences DESC\n",
        "                        \"\"\"\n",
        "\n",
        "result_test3 = spark.sql(third_problem_query1)   #.createOrReplaceTempView(\"third_query_test\")\n",
        "result_test3.show()\n",
        "\n",
        "# -----------------------4th Problem mitigation ----------------#\n",
        "\n",
        "fourth_problem_query = \"\"\"\n",
        "                with cte_popular_move_win as (\n",
        "                select A.eco, A.eco_name, B.game_id,B.winner_elo\n",
        "                from eco_codesTemp A left join chess_wc_history_game_infoTemp1 B\n",
        "                on A.eco = B.eco\n",
        "                where B.winner_elo is not null\n",
        "                )\n",
        "                select eco, eco_name ,winner_elo,\n",
        "                count(*) over (partition by eco order by eco) as occurance\n",
        "                from cte_popular_move_win\n",
        "                group by eco,eco_name,winner_elo\n",
        "                order by occurance DESC\n",
        "                --limit 1\n",
        "\"\"\"\n",
        "spark.sql(fourth_problem_query).createOrReplaceTempView(\"fourth_problem_query0\")\n",
        "#r = spark.sql(\"select * from fourth_problem_query0  order by occurance DEsc  limit 10\")\n",
        "#r.show()\n",
        "\n",
        "fourth_problem_query1 = \"\"\"\n",
        "                with CTE_final AS (\n",
        "                select eco, eco_name ,occurance,\n",
        "                ROW_NUMBER() over(order by occurance DESC) as row_num\n",
        "                from fourth_problem_query0 )\n",
        "                select eco, eco_name  --, occurance, row_num\n",
        "                from CTE_final\n",
        "                where  row_num=1\n",
        "                order by occurance DESC\n",
        "\n",
        "\"\"\"\n",
        "result_test4 = spark.sql(fourth_problem_query1 )\n",
        "result_test4.show()\n",
        "\n",
        "# -----------------------5th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "chess_wc_history_game_infoTempTable.createOrReplaceTempView(\"chess_wc_history_game_infoTempTable1\")\n",
        "chess_wc_history_movesTempTable.createOrReplaceTempView(\"chess_wc_history_movesTempTable1\")\n",
        "\n",
        "#test  = spark.sql(\"select game_id, event ,\")\n",
        "\n",
        "# move_no , move_Sequence(even number shoub be there),game_id,event, tournament_name\n",
        "#Longest and shortest game ever played in a world championship in terms of move\n",
        "# Final result will have only two rows\n",
        "fifth_problem_query0 = \"\"\"\n",
        "                        with cte_test_move as (\n",
        "                        select\n",
        "                        A.game_id,B.date_played,\n",
        "                        A.move_no, A.move_no_pair ,\n",
        "                        A.move_Sequence,\n",
        "                        B.event, B.tournament_name,\n",
        "                        B.winner,\n",
        "                        B.loser,\n",
        "                        B.winner_elo,\n",
        "                        B.loser_elo,\n",
        "                        ROW_NUMBER() over(partition by A.game_id, B.date_played order by A.move_Sequence DESC) as longest_move_rank\n",
        "                        --ROW_NUMBER() over(partition by A.game_id, B.date_played order by A.move_Sequence ASC) as shortest_move_rank\n",
        "                        from chess_wc_history_movesTempTable1 A left join chess_wc_history_game_infoTempTable1 B\n",
        "                        on A.game_id =  B.game_id )\n",
        "                        select game_id, date_played,\n",
        "                        --move_no,\n",
        "                        --longest_move_rank as move_rank,\n",
        "                        move_no_pair,\n",
        "                        move_Sequence, event,tournament_name,winner,loser,\n",
        "                        ROW_NUMBER() over(order by move_no_pair DESC) as high_rank,\n",
        "                        --ROW_NUMBER() over(order by move_no_pair ASC) as low_rank,\n",
        "                        winner_elo,loser_elo\n",
        "                        from cte_test_move\n",
        "                        where longest_move_rank = 1 and move_no_pair%2 = 0               --in (1,2,3,4)\n",
        "                         and event is not null\n",
        "                        --group by game_id, date_played, move_no_pair ,move_no\n",
        "                        order by move_no_pair DESC\n",
        "\n",
        "\"\"\"\n",
        "spark.sql(fifth_problem_query0).createOrReplaceTempView(\"fifth_problem_query1\")\n",
        "\n",
        "fifth_problem_query2 = \"\"\"\n",
        "                      WITH CTE_Final AS (\n",
        "                      SELECT\n",
        "                      game_id,\n",
        "                      event,\n",
        "                      tournament_name,\n",
        "                      move_no_pair AS number_of_moves,\n",
        "                      ROW_NUMBER() OVER ( ORDER BY move_no_pair DESC) AS longest_game_played,\n",
        "                      ROW_NUMBER() OVER ( ORDER BY move_no_pair ASC) AS shortest_game_played,\n",
        "                      move_sequence\n",
        "                      FROM fifth_problem_query1\n",
        "                      )\n",
        "                    SELECT\n",
        "                    game_id,\n",
        "                    event,\n",
        "                    tournament_name,\n",
        "                    number_of_moves\n",
        "                    FROM CTE_Final\n",
        "                    WHERE longest_game_played = 1 OR shortest_game_played = 1\n",
        "                    ORDER BY number_of_moves DESC \"\"\"\n",
        "\n",
        "result_test5 = spark.sql(fifth_problem_query2)\n",
        "result_test5.show()\n",
        "\n",
        "# -----------------------6th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "sixth_problem_query0 = \"\"\"\n",
        "                        with cte_final_sixth as (\n",
        "                        select\n",
        "                        game_id,\n",
        "                        event,\n",
        "                        tournament_name,\n",
        "                        move_no_pair as number_of_moves,\n",
        "                        ROW_NUMBER()over(order by move_no_pair DESC)as high_rank_draw,\n",
        "                        ROW_NUMBER()over(order by move_no_pair ASC)as low_rank_draw\n",
        "                        from fifth_problem_query1\n",
        "                        where winner like '%draw%' )\n",
        "                        select\n",
        "                        game_id,\n",
        "                        event,\n",
        "                        tournament_name,\n",
        "                        number_of_moves\n",
        "                        from cte_final_sixth\n",
        "                        where high_rank_draw = 1 or low_rank_draw = 1\n",
        "                        order by number_of_moves DESC\"\"\"\n",
        "\n",
        "result_test6 = spark.sql(sixth_problem_query0)\n",
        "result_test6.show()\n",
        "\n",
        "# -----------------------7th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "seventh_problem_query0 = \"\"\"\n",
        "                        with cte_Final_playerRanks as (\n",
        "                        select\n",
        "                        winner as player_name ,\n",
        "                        winner_elo as elo,\n",
        "                        ROW_NUMBER() over ( order by winner_elo DESC) as ranking_high,\n",
        "                        ROW_NUMBER() over ( order by winner_elo ASC) as ranking_low\n",
        "                        from chess_wc_history_game_infoTempTable1\n",
        "                        where winner_elo is not null and loser_elo is not null )\n",
        "                        select player_name, elo\n",
        "                        from cte_Final_playerRanks\n",
        "                        where ranking_high =1  or ranking_low = 1\n",
        "                        order by elo DESC\n",
        "\"\"\"\n",
        "\n",
        "result_test7 = spark.sql(seventh_problem_query0)\n",
        "result_test7.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ-Zo_yS2Zuu",
        "outputId": "7685d30e-7011-4ef3-886b-91f861811839"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|              winner|tournament_name|\n",
            "+--------------------+---------------+\n",
            "|           Carlsen,M| WorldChamp2021|\n",
            "|     Carlsen, Magnus| WorldChamp2016|\n",
            "|     Carlsen, Magnus| WorldChamp2014|\n",
            "|     Carlsen, Magnus| WorldChamp2013|\n",
            "|           Gelfand,B| WorldChamp2012|\n",
            "|             Anand,V| WorldChamp2010|\n",
            "|             Anand,V| WorldChamp2008|\n",
            "|             Anand,V| WorldChamp2007|\n",
            "|           Kramnik,V| WorldChamp2006|\n",
            "|              Leko,P| WorldChamp2004|\n",
            "|           Kramnik,V| WorldChamp2000|\n",
            "|      Kasparov, Gary| WorldChamp1990|\n",
            "|      Kasparov, Gary| WorldChamp1987|\n",
            "|      Kasparov, Gary| WorldChamp1986|\n",
            "|      Kasparov, Gary| WorldChamp1985|\n",
            "|     Karpov, Anatoly| WorldChamp1984|\n",
            "|     Karpov, Anatoly| WorldChamp1981|\n",
            "|     Karpov, Anatoly| WorldChamp1978|\n",
            "|Fischer, Robert J...| WorldChamp1972|\n",
            "|    Spassky, Boris V| WorldChamp1969|\n",
            "+--------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+--------------+\n",
            "|         Player_name|number_of_wins|\n",
            "+--------------------+--------------+\n",
            "|     Lasker, Emanuel|             6|\n",
            "|  Botvinnik, Mikhail|             5|\n",
            "|      Kasparov, Gary|             4|\n",
            "|   Steinitz, William|             4|\n",
            "| Alekhine, Alexander|             4|\n",
            "|     Carlsen, Magnus|             3|\n",
            "|     Karpov, Anatoly|             3|\n",
            "|             Anand,V|             3|\n",
            "| Petrosian, Tigran V|             2|\n",
            "|           Kramnik,V|             2|\n",
            "|           Carlsen,M|             1|\n",
            "|              Leko,P|             1|\n",
            "|    Spassky, Boris V|             1|\n",
            "|    Schlechter, Carl|             1|\n",
            "|           Euwe, Max|             1|\n",
            "|Fischer, Robert J...|             1|\n",
            "|    Smyslov, Vassily|             1|\n",
            "|         Tal, Mihail|             1|\n",
            "|           Gelfand,B|             1|\n",
            "|Capablanca, Jose ...|             1|\n",
            "+--------------------+--------------+\n",
            "\n",
            "+---+-----------------+--------------------+\n",
            "|eco|         eco_name|number_of_occurences|\n",
            "+---+-----------------+--------------------+\n",
            "|B89|         Sicilian|                  15|\n",
            "|D97|Grunfeld, Russian|                   1|\n",
            "+---+-----------------+--------------------+\n",
            "\n",
            "+---+--------------+\n",
            "|eco|      eco_name|\n",
            "+---+--------------+\n",
            "|C42|Petrov Defense|\n",
            "+---+--------------+\n",
            "\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|             game_id|               event|tournament_name|number_of_moves|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|58e83255-93bb-4d5...|            WCh 2021| WorldChamp2021|            136|\n",
            "|7e3065e9-94cc-4ee...|World Championshi...| WorldChamp1963|             10|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|             game_id|               event|tournament_name|number_of_moves|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|bf66c982-f6c5-4e7...|World Championshi...| WorldChamp1978|            124|\n",
            "|7e3065e9-94cc-4ee...|World Championshi...| WorldChamp1963|             10|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "\n",
            "+---------------+----+\n",
            "|    player_name| elo|\n",
            "+---------------+----+\n",
            "|Carlsen, Magnus|2870|\n",
            "|  Timman, Jan H|2620|\n",
            "+---------------+----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}