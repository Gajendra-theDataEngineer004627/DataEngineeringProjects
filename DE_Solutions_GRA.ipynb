{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9YlUklWZ6g59Z96v4FMef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gajendra-theDataEngineer004627/DataEngineeringProjects/blob/ChessChampionshipProject/DE_Solutions_GRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_uWVNb5Ai3V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce73f90-c16d-43d5-f412-4352048ec8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [82.8 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [37.5 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,529 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,866 kB]\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,070 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,670 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,604 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,369 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [40.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,346 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,230 kB]\n",
            "Fetched 18.2 MB in 4s (4,579 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "af-JE2bHjxxM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "Ne1MHHMdkO7x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "XgZd6iOskebJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "jnjdlT4CkjII"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "ACgBCh7PktWA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = (SparkSession\n",
        " .builder\n",
        " .appName(\"<app_name>\")\n",
        " .getOrCreate())\n"
      ],
      "metadata": {
        "id": "ob8j-c-ckx4I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to doanload data files from the google drive\n",
        "import gdown\n",
        "def downloadfiles_fromFolder() :\n",
        "    url = \"https://drive.google.com/drive/folders/1QgWPHV_l25Ui9L7et8mkZohAOG59UTkQ\"   # can also be used input()\n",
        "    if url.split(\"/\")[-1]== \"?usp=sharing\":\n",
        "       url = url.replace(\"?usp=sharing\",\"\")\n",
        "    gdown.download_folder(url, output=\"/content\")\n",
        "\n",
        "downloadfiles_fromFolder()"
      ],
      "metadata": {
        "id": "egBrBPncpxL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the datasets for each data files and understanding the data\n",
        "\n",
        "chess_wc_history_game_info = spark.read.load(\"/content/chess_wc_history_game_info.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "chess_wc_history_moves = spark.read.load(\"/content/chess_wc_history_moves.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "eco_codes = spark.read.load(\"/content/eco_codes.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n"
      ],
      "metadata": {
        "id": "ciwD1tV_w6G4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the top 10 records are properly loaded or not\n",
        "# print(chess_wc_history_moves.head())\n",
        "# print(eco_codes.head())\n",
        "# print(chess_wc_history_game_info.head())"
      ],
      "metadata": {
        "id": "44qmU1Vo0eSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating temporary view for data manupulations\n",
        "chess_wc_history_moves.createOrReplaceTempView(\"chess_wc_history_movesTemp\")\n",
        "eco_codes.createOrReplaceTempView(\"eco_codesTemp\")\n",
        "chess_wc_history_game_info.createOrReplaceTempView(\"chess_wc_history_game_infoTemp\")\n",
        "\n",
        "# ----Creating the table from the temp view so that the tables can be accessible globally(accessed across different Spark sessions) #\n",
        "\n",
        "query_main_Event  = \"\"\"Select * from chess_wc_history_game_infoTemp where\n",
        "                        event not like '%KO%' and\n",
        "                        event not like '%k.o.%' \"\"\"\n",
        "\n",
        "\n",
        "# -------------WCh knock out(string with k.o.,KO ) are not included in main event-----------#\n",
        "spark.sql(query_main_Event).createOrReplaceTempView(\"chess_wc_history_game_infoTemp1\")\n",
        "\n",
        "\n",
        "chess_wc_history_movesTempTable = spark.table(\"chess_wc_history_movesTemp\")\n",
        "eco_codesTempTable = spark.table(\"eco_codesTemp\")\n",
        "chess_wc_history_game_infoTempTable = spark.table(\"chess_wc_history_game_infoTemp1\")\n",
        "\n",
        "# Checking the validity of data in table form  using mysql like capabilities in SparkSql\n",
        "#result1 = spark.sql(\"SELECT * FROM chess_wc_history_movesTemp limit 5\")\n",
        "#result1.show()\n",
        "#result2 = spark.sql(\"SELECT * FROM eco_codesTemp\")\n",
        "#result2.show()\n",
        "# result2.printSchema()    # --> to check schema\n",
        "  # result3 = spark.sql(\"SELECT * from chess_wc_history_game_infoTemp limit 5 \")\n",
        "  # result3.show()\n",
        " #spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
        "  # eco_codes.columns    # this is used to check the data frames columns\n",
        "  #chess_wc_history_game_info.columns\n",
        "\n",
        "\n",
        "query1 = \"\"\" WITH CTE_WInner_List AS\n",
        "                (select winner , event,round , tournament_name,date_played,\n",
        "                count(*) over (partition by winner,tournament_name order by date_played) as WinnerCount\n",
        "                from chess_wc_history_game_infoTemp1\n",
        "                where winner not like '%draw%'and\n",
        "                tournament_name like 'WorldChamp%' )\n",
        "                SELECT winner, tournament_name, MAX(WinnerCount) AS Score\n",
        "                FROM CTE_Winner_List\n",
        "                GROUP BY winner ,tournament_name\n",
        "                order BY tournament_name DESC\n",
        "\"\"\"\n",
        "spark.sql(query1).createOrReplaceTempView(\"temp_view1\")\n",
        "\n",
        "final_query1 = \"\"\" with CTE_Final AS (\n",
        "                select winner, tournament_name, Score ,\n",
        "                ROW_NUMBER() OVER (partition by tournament_name order by Score DESC) as Row_num\n",
        "                from temp_view1 )\n",
        "                select winner, tournament_name  --, Score\n",
        "                from CTE_Final\n",
        "                where Row_num = 1\n",
        "                order by tournament_name DESC\n",
        "\"\"\"\n",
        "\n",
        "#  -----------Sollution of 1st Problem ----------------#\n",
        "resultTest1 = spark.sql(final_query1)\n",
        "resultTest1.show()\n",
        "# TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB\n",
        "#resultTest1.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb1\", header=True)\n",
        "# -----------------------2nd Problem mitigation ----------------#\n",
        "spark.sql(final_query1).createOrReplaceTempView(\"Second_problem\")\n",
        "\n",
        "second_problem_query1  = \"\"\"\n",
        "        select winner as Player_name,\n",
        "        count(*) as number_of_wins from Second_problem\n",
        "        group by winner\n",
        "        order by number_of_wins DESC\n",
        "\"\"\"\n",
        "#  -----------Sollution of 2nd Problem ----------------#\n",
        "resultTest2 = spark.sql(second_problem_query1)\n",
        "resultTest2.show()\n",
        "# TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB\n",
        "#resultTest2.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb2\", header=True)\n",
        "# -----------------------3rd Problem mitigation ----------------#\n",
        "\n",
        "third_problem_query0 = \"\"\"\n",
        "                with cte_popular_move as (\n",
        "                select A.eco, A.eco_name, B.game_id,\n",
        "                count(*) over(partition by A.eco, B.game_id  order by A.eco) as no_of_occurances\n",
        "                from eco_codesTemp A left join chess_wc_history_game_infoTemp1 B\n",
        "                on A.eco = B.eco )\n",
        "                select eco, eco_name ,\n",
        "                count(*) over(partition by eco_name order by eco) as occurance\n",
        "                from cte_popular_move\n",
        "                group by eco,eco_name\n",
        "                order by occurance DESC\n",
        "\"\"\"\n",
        "\n",
        "test_res6 = spark.sql(third_problem_query0).createOrReplaceTempView(\"third_query_test0\")\n",
        "#test_res6.show()\n",
        "\n",
        "third_problem_query1 = \"\"\"with cte_test_final as (\n",
        "                        select eco, eco_name,\n",
        "                        occurance as number_of_occurences,\n",
        "                        ROW_NUMBER() over( order by occurance DESC) as MostRow,\n",
        "                        ROW_NUMBER() over( order by occurance ASC) as leastRow\n",
        "                        from third_query_test0 )\n",
        "                        select\n",
        "                        eco,\n",
        "                        eco_name,\n",
        "                        number_of_occurences   --,MostRow, leastRow\n",
        "                        from cte_test_final\n",
        "                        where  MostRow =1 or leastRow = 1\n",
        "                        order by number_of_occurences DESC\n",
        "                        \"\"\"\n",
        "\n",
        "#  -----------Sollution of 3rd Problem ----------------#\n",
        "result_test3 = spark.sql(third_problem_query1)   #.createOrReplaceTempView(\"third_query_test\")\n",
        "result_test3.show()\n",
        "\n",
        "# -----------------------4th Problem mitigation ----------------#\n",
        "\n",
        "fourth_problem_query = \"\"\"\n",
        "                with cte_popular_move_win as (\n",
        "                select A.eco, A.eco_name, B.game_id,B.winner_elo\n",
        "                from eco_codesTemp A left join chess_wc_history_game_infoTemp1 B\n",
        "                on A.eco = B.eco\n",
        "                where B.winner_elo is not null\n",
        "                )\n",
        "                select eco, eco_name ,winner_elo,\n",
        "                count(*) over (partition by eco order by eco) as occurance\n",
        "                from cte_popular_move_win\n",
        "                group by eco,eco_name,winner_elo\n",
        "                order by occurance DESC\n",
        "                --limit 1\n",
        "\"\"\"\n",
        "spark.sql(fourth_problem_query).createOrReplaceTempView(\"fourth_problem_query0\")\n",
        "#r = spark.sql(\"select * from fourth_problem_query0  order by occurance DEsc  limit 10\")\n",
        "#r.show()\n",
        "\n",
        "fourth_problem_query1 = \"\"\"\n",
        "                with CTE_final AS (\n",
        "                select eco, eco_name ,occurance,\n",
        "                ROW_NUMBER() over(order by occurance DESC) as row_num\n",
        "                from fourth_problem_query0 )\n",
        "                select eco, eco_name  --, occurance, row_num\n",
        "                from CTE_final\n",
        "                where  row_num=1\n",
        "                order by occurance DESC \"\"\"\n",
        "\n",
        "#  -----------Sollution of 4th Problem ----------------#\n",
        "result_test4 = spark.sql(fourth_problem_query1 )\n",
        "result_test4.show()\n",
        "\n",
        "# -----------------------5th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "chess_wc_history_game_infoTempTable.createOrReplaceTempView(\"chess_wc_history_game_infoTempTable1\")\n",
        "chess_wc_history_movesTempTable.createOrReplaceTempView(\"chess_wc_history_movesTempTable1\")\n",
        "\n",
        "#test  = spark.sql(\"select game_id, event ,\")\n",
        "\n",
        "# move_no , move_Sequence(even number shoub be there),game_id,event, tournament_name\n",
        "#Longest and shortest game ever played in a world championship in terms of move\n",
        "# Final result will have only two rows\n",
        "fifth_problem_query0 = \"\"\"\n",
        "                        with cte_test_move as (\n",
        "                        select\n",
        "                        A.game_id,B.date_played,\n",
        "                        A.move_no, A.move_no_pair ,\n",
        "                        A.move_Sequence,\n",
        "                        B.event, B.tournament_name,\n",
        "                        B.winner,\n",
        "                        B.loser,\n",
        "                        B.winner_elo,\n",
        "                        B.loser_elo,\n",
        "                        ROW_NUMBER() over(partition by A.game_id, B.date_played order by A.move_Sequence DESC) as longest_move_rank\n",
        "                        --ROW_NUMBER() over(partition by A.game_id, B.date_played order by A.move_Sequence ASC) as shortest_move_rank\n",
        "                        from chess_wc_history_movesTempTable1 A left join chess_wc_history_game_infoTempTable1 B\n",
        "                        on A.game_id =  B.game_id )\n",
        "                        select game_id, date_played,\n",
        "                        --move_no,\n",
        "                        --longest_move_rank as move_rank,\n",
        "                        move_no_pair,\n",
        "                        move_Sequence, event,tournament_name,winner,loser,\n",
        "                        ROW_NUMBER() over(order by move_no_pair DESC) as high_rank,\n",
        "                        --ROW_NUMBER() over(order by move_no_pair ASC) as low_rank,\n",
        "                        winner_elo,loser_elo\n",
        "                        from cte_test_move\n",
        "                        where longest_move_rank = 1 and move_no_pair%2 = 0               --in (1,2,3,4)\n",
        "                         and event is not null\n",
        "                        --group by game_id, date_played, move_no_pair ,move_no\n",
        "                        order by move_no_pair DESC\n",
        "\n",
        "\"\"\"\n",
        "spark.sql(fifth_problem_query0).createOrReplaceTempView(\"fifth_problem_query1\")\n",
        "\n",
        "fifth_problem_query2 = \"\"\"\n",
        "                      WITH CTE_Final AS (\n",
        "                      SELECT\n",
        "                      game_id,\n",
        "                      event,\n",
        "                      tournament_name,\n",
        "                      move_no_pair AS number_of_moves,\n",
        "                      ROW_NUMBER() OVER ( ORDER BY move_no_pair DESC) AS longest_game_played,\n",
        "                      ROW_NUMBER() OVER ( ORDER BY move_no_pair ASC) AS shortest_game_played,\n",
        "                      move_sequence\n",
        "                      FROM fifth_problem_query1\n",
        "                      )\n",
        "                    SELECT\n",
        "                    game_id,\n",
        "                    event,\n",
        "                    tournament_name,\n",
        "                    number_of_moves\n",
        "                    FROM CTE_Final\n",
        "                    WHERE longest_game_played = 1 OR shortest_game_played = 1\n",
        "                    ORDER BY number_of_moves DESC \"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 5th Problem ----------------#\n",
        "result_test5 = spark.sql(fifth_problem_query2)\n",
        "result_test5.show()\n",
        "\n",
        "# -----------------------6th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "sixth_problem_query0 = \"\"\"\n",
        "                        with cte_final_sixth as (\n",
        "                        select\n",
        "                        game_id,\n",
        "                        event,\n",
        "                        tournament_name,\n",
        "                        move_no_pair as number_of_moves,\n",
        "                        ROW_NUMBER()over(order by move_no_pair DESC)as high_rank_draw,\n",
        "                        ROW_NUMBER()over(order by move_no_pair ASC)as low_rank_draw\n",
        "                        from fifth_problem_query1\n",
        "                        where winner like '%draw%' )\n",
        "                        select\n",
        "                        game_id,\n",
        "                        event,\n",
        "                        tournament_name,\n",
        "                        number_of_moves\n",
        "                        from cte_final_sixth\n",
        "                        where high_rank_draw = 1 or low_rank_draw = 1\n",
        "                        order by number_of_moves DESC\"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 6th Problem ----------------#\n",
        "result_test6 = spark.sql(sixth_problem_query0)\n",
        "result_test6.show()\n",
        "\n",
        "# -----------------------7th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "seventh_problem_query0 = \"\"\"\n",
        "                        with cte_Final_playerRanks as (\n",
        "                        select\n",
        "                        winner as player_name ,\n",
        "                        winner_elo as elo,\n",
        "                        ROW_NUMBER() over ( order by winner_elo DESC) as ranking_high,\n",
        "                        ROW_NUMBER() over ( order by winner_elo ASC) as ranking_low\n",
        "                        from chess_wc_history_game_infoTempTable1\n",
        "                        where winner_elo is not null and loser_elo is not null )\n",
        "                        select player_name, elo\n",
        "                        from cte_Final_playerRanks\n",
        "                        where ranking_high =1  or ranking_low = 1\n",
        "                        order by elo DESC\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 7th Problem ----------------#\n",
        "result_test7 = spark.sql(seventh_problem_query0)\n",
        "result_test7.show()\n",
        "\n",
        "\n",
        "# -----------------------8th Problem mitigation ----------------#\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "eighth_problem_query0 = \"\"\"\n",
        "                with cte_final_mostlossPlayer as (\n",
        "                select\n",
        "                game_id,\n",
        "                loser as player_name,\n",
        "                event,\n",
        "                count(*) over(partition by loser order by event) as loss_countofPlayer\n",
        "                from  chess_wc_history_game_infoTempTable1 )\n",
        "                select distinct\n",
        "                player_name ,\n",
        "                loss_countofPlayer\n",
        "                --ROW_NUMBER() over( partition by player_name, loss_countofPlayer  order by loss_countofPlayer DESC) as loss_ranking\n",
        "                from cte_final_mostlossPlayer\n",
        "                where player_name not like '%draw%'\n",
        "                order by loss_countofPlayer DESC\n",
        " \"\"\"\n",
        "spark.sql(eighth_problem_query0).createOrReplaceTempView(\"eighth_problem_test1\")\n",
        "\n",
        "\n",
        "# this below query will give unique records of the highest loss the person has taken in overall\n",
        "# used the offset to skip 1st 2 rows of sorted table and getting the 3rd Last Player with most Loss\n",
        "eighth_problem_query1 = \"\"\"\n",
        "                        with cte_intermediate_lossdetails as (\n",
        "                        select\n",
        "                        player_name,\n",
        "                        loss_countofPlayer,\n",
        "                        ROW_NUMBER() over(partition by player_name order by loss_countofPlayer DESC) as row_num1\n",
        "                        from eighth_problem_test1 )\n",
        "                        select\n",
        "                        player_name,\n",
        "                        loss_countofPlayer\n",
        "                        from cte_intermediate_lossdetails\n",
        "                        where row_num1 = 1\n",
        "                        group by player_name,loss_countofPlayer\n",
        "                        order by loss_countofPlayer DESC\n",
        "                        --limit 1 offset 2\n",
        "\"\"\"\n",
        "spark.sql(eighth_problem_query1).createOrReplaceTempView(\"eighth_problem_test2\")\n",
        "\n",
        "eighth_problem_query2 =\"\"\"\n",
        "                        with cte_Final as (\n",
        "                        select\n",
        "                        player_name  ,\n",
        "                        loss_countofPlayer ,\n",
        "                        RANK() over( order by loss_countofPlayer DESC) as rank\n",
        "                        from eighth_problem_test2 )\n",
        "                        select player_name\n",
        "                        from cte_Final\n",
        "                        where rank = 3\"\"\"\n",
        "\n",
        "#  -----------Sollution of 8th Problem ----------------#\n",
        "result_test8 = spark.sql(eighth_problem_query2)\n",
        "result_test8.show()\n",
        "\n",
        "# -----------------------9th Problem mitigation ----------------#\n",
        "# How many times players with low rating won matches with their total win Count.\n",
        "# Result attributes: player_name, win_count\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "#Required fields - game_id , event, tournament_name,winner,winner_elo,loser,loser_elo, date_played\n",
        "\n",
        "ninth_problem_query = \"\"\"\n",
        "                        with cte_lowRankWinner as (\n",
        "                        select\n",
        "                        --A.game_id,\n",
        "                        --A.date_played,\n",
        "                        --A.event,\n",
        "                        --A.tournament_name,\n",
        "                        A.winner,A.winner_elo,\n",
        "                        count(*) over(partition by A.winner order by A.winner) as countOfLowRankWinners,\n",
        "                        Row_Number() over(partition by A.winner order by A.winner) as row_num,\n",
        "                        B.loser,B.loser_elo\n",
        "                        from chess_wc_history_game_infoTempTable1 A left join chess_wc_history_game_infoTempTable1 B\n",
        "                        on A.game_id = B.game_id\n",
        "                        where A.winner not like '%draw%'and A.winner_elo is not null\n",
        "                        and B.loser_elo > A.winner_elo\n",
        "                        group by A.winner,A.winner_elo,B.loser,B.loser_elo )\n",
        "                        select\n",
        "                        winner as player_name,\n",
        "                        countOfLowRankWinners as win_count\n",
        "                        from cte_lowRankWinner\n",
        "                        where row_num = 1\n",
        "                        order by countOfLowRankWinners DESC\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 9th Problem ----------------#\n",
        "resultTest9 = spark.sql(ninth_problem_query)\n",
        "resultTest9.show()\n",
        "#---------- TO DOWNLOAD FILES TO THE CONTENT FOLDER OF COLAB ------------#\n",
        "#resultTest9.coalesce(1).write.mode(\"overwrite\").csv(\"/content/resultTest_prb9\", header=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------10th Problem mitigation ----------------#\n",
        "# Move Sequence for Each Player in a Match.\n",
        "# Result attributes: game_id, player_name, move_sequence, move_count\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "#chess_wc_history_game_infoTempTable.show()\n",
        "\n",
        "# REquired fields : game_id, move_no, move_no_pair, player , move , move_sequence\n",
        "\n",
        "tenth_problem_query = \"\"\"\n",
        "                        with cte_movSequence as (\n",
        "                        select\n",
        "                        game_id, move_no,\n",
        "                        move_no_pair, player , notation,\n",
        "                        move , move_sequence,\n",
        "                        ROW_NUMBER()over(partition by game_id,player order by move_no_pair DESC) as movRowSeq\n",
        "                        from chess_wc_history_movesTemp )\n",
        "                        select\n",
        "                        game_id,\n",
        "                        player as player_name ,\n",
        "                        move_sequence,\n",
        "                        move_no as move_count\n",
        "                        --(LENGTH(move_sequence) - LENGTH(REPLACE(move_sequence, '|', '')) + 1) AS move_count,\n",
        "                        --movRowSeq\n",
        "                        from cte_movSequence\n",
        "                        where movRowSeq = 1\n",
        "                        order by  move_no DESC \"\"\"\n",
        "\n",
        "\n",
        "#  -----------Sollution of 10th Problem ----------------#\n",
        "result_test10 = spark.sql(tenth_problem_query)\n",
        "result_test10.show()\n",
        "\n",
        "\n",
        "# -----------------------11th Problem mitigation ----------------#\n",
        "\n",
        "#Total Number of games where losing player has more Captured score than Winning player.\n",
        "#Hint: Captured score is cumulative, i.e., for 3rd capture it will have score for 1, 2, and 3rd.\n",
        "#Result attributes: total_number_of_games Final result will have only one row\n",
        "\n",
        "#chess_wc_history_movesTempTable.show()\n",
        "#eco_codesTempTable.show()\n",
        "\n",
        "\n",
        "# REquired fields :\n",
        "# from chess_wc_history_movesTemp - captured_score_for_white,captured_score_for_black , game_id,\n",
        "# from chess_wc_history_game_infoTempTable1 : winner, winner_elo, loser,loser_elo ,game_id\n",
        "\n",
        "eleventh_problem_query0 = \"\"\"\n",
        "                        select\n",
        "                        distinct\n",
        "                        game_id,\n",
        "                        sum(captured_score_for_white) over(partition by game_id order by game_id) as CumilativeOfWhite,\n",
        "                        sum(captured_score_for_black) over(partition by game_id order by game_id) as CumilativeOfBlack\n",
        "                        from chess_wc_history_movesTemp\n",
        "                        where captured_score_for_white != 0 and captured_score_for_black !=0\n",
        "\n",
        "\"\"\"\n",
        "spark.sql(eleventh_problem_query0).createOrReplaceTempView(\"eleventh_query1\")\n",
        "\n",
        "eleventh_problem_query1 = \"\"\"\n",
        "                        select\n",
        "                        A.game_id,\n",
        "                        A.CumilativeOfWhite,\n",
        "                        A.CumilativeOfBlack,\n",
        "                        B.white, B.black,\n",
        "                        B.winner,B.loser\n",
        "                        from  eleventh_query1 A left join  chess_wc_history_game_infoTempTable1 B\n",
        "                        on A.game_id = B.game_id\n",
        "                        where B.winner not like '%draw%' and B.winner_elo is not null\n",
        "\n",
        "\"\"\"\n",
        "spark.sql(eleventh_problem_query1).createOrReplaceTempView(\"eleventh_query2\")\n",
        "eleventh_problem_query2 = \"\"\"\n",
        "                        with cte_finalGameScore as (\n",
        "                        select\n",
        "                        game_id ,\n",
        "                        case\n",
        "                        when winner == black then CumilativeOfBlack\n",
        "                                else CumilativeOfWhite\n",
        "                        end as winnerScore,\n",
        "                        case\n",
        "                        when loser == black then CumilativeOfBlack\n",
        "                                else CumilativeOfWhite\n",
        "                        end as loserScore,\n",
        "                        CumilativeOfBlack,\n",
        "                        CumilativeOfWhite,\n",
        "                        white,black,\n",
        "                        winner, loser\n",
        "                        from eleventh_query2 )\n",
        "                        select\n",
        "                        count(*) as total_number_of_games\n",
        "                        from cte_finalGameScore\n",
        "                        where loserScore > winnerScore\n",
        "\n",
        "\"\"\"\n",
        "#  -----------Sollution of 11th Problem ----------------#\n",
        "result_test11 = spark.sql(eleventh_problem_query2)\n",
        "result_test11.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ-Zo_yS2Zuu",
        "outputId": "231b07c8-8961-48cd-9441-919e78ad3be0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+\n",
            "|              winner|tournament_name|\n",
            "+--------------------+---------------+\n",
            "|           Carlsen,M| WorldChamp2021|\n",
            "|     Carlsen, Magnus| WorldChamp2016|\n",
            "|     Carlsen, Magnus| WorldChamp2014|\n",
            "|     Carlsen, Magnus| WorldChamp2013|\n",
            "|           Gelfand,B| WorldChamp2012|\n",
            "|             Anand,V| WorldChamp2010|\n",
            "|             Anand,V| WorldChamp2008|\n",
            "|             Anand,V| WorldChamp2007|\n",
            "|           Kramnik,V| WorldChamp2006|\n",
            "|              Leko,P| WorldChamp2004|\n",
            "|           Kramnik,V| WorldChamp2000|\n",
            "|      Kasparov, Gary| WorldChamp1990|\n",
            "|      Kasparov, Gary| WorldChamp1987|\n",
            "|      Kasparov, Gary| WorldChamp1986|\n",
            "|      Kasparov, Gary| WorldChamp1985|\n",
            "|     Karpov, Anatoly| WorldChamp1984|\n",
            "|     Karpov, Anatoly| WorldChamp1981|\n",
            "|     Karpov, Anatoly| WorldChamp1978|\n",
            "|Fischer, Robert J...| WorldChamp1972|\n",
            "|    Spassky, Boris V| WorldChamp1969|\n",
            "+--------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+--------------+\n",
            "|         Player_name|number_of_wins|\n",
            "+--------------------+--------------+\n",
            "|     Lasker, Emanuel|             6|\n",
            "|  Botvinnik, Mikhail|             5|\n",
            "|      Kasparov, Gary|             4|\n",
            "| Alekhine, Alexander|             4|\n",
            "|   Steinitz, William|             4|\n",
            "|             Anand,V|             3|\n",
            "|     Carlsen, Magnus|             3|\n",
            "|     Karpov, Anatoly|             3|\n",
            "|           Kramnik,V|             2|\n",
            "| Petrosian, Tigran V|             2|\n",
            "|           Carlsen,M|             1|\n",
            "|Fischer, Robert J...|             1|\n",
            "|              Leko,P|             1|\n",
            "|    Schlechter, Carl|             1|\n",
            "|    Spassky, Boris V|             1|\n",
            "|Capablanca, Jose ...|             1|\n",
            "|         Tal, Mihail|             1|\n",
            "|           Gelfand,B|             1|\n",
            "|    Smyslov, Vassily|             1|\n",
            "|           Euwe, Max|             1|\n",
            "+--------------------+--------------+\n",
            "\n",
            "+---+-----------------+--------------------+\n",
            "|eco|         eco_name|number_of_occurences|\n",
            "+---+-----------------+--------------------+\n",
            "|B89|         Sicilian|                  15|\n",
            "|D97|Grunfeld, Russian|                   1|\n",
            "+---+-----------------+--------------------+\n",
            "\n",
            "+---+--------------+\n",
            "|eco|      eco_name|\n",
            "+---+--------------+\n",
            "|C42|Petrov Defense|\n",
            "+---+--------------+\n",
            "\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|             game_id|               event|tournament_name|number_of_moves|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|58e83255-93bb-4d5...|            WCh 2021| WorldChamp2021|            136|\n",
            "|7e3065e9-94cc-4ee...|World Championshi...| WorldChamp1963|             10|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|             game_id|               event|tournament_name|number_of_moves|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "|bf66c982-f6c5-4e7...|World Championshi...| WorldChamp1978|            124|\n",
            "|7e3065e9-94cc-4ee...|World Championshi...| WorldChamp1963|             10|\n",
            "+--------------------+--------------------+---------------+---------------+\n",
            "\n",
            "+---------------+----+\n",
            "|    player_name| elo|\n",
            "+---------------+----+\n",
            "|Carlsen, Magnus|2870|\n",
            "|  Timman, Jan H|2620|\n",
            "+---------------+----+\n",
            "\n",
            "+---------------+\n",
            "|    player_name|\n",
            "+---------------+\n",
            "|Karpov, Anatoly|\n",
            "+---------------+\n",
            "\n",
            "+------------------+---------+\n",
            "|       player_name|win_count|\n",
            "+------------------+---------+\n",
            "|   Karpov, Anatoly|        4|\n",
            "|      Morozevich,A|        3|\n",
            "|         Gelfand,B|        3|\n",
            "|         Kramnik,V|        3|\n",
            "|            Leko,P|        2|\n",
            "|Kortschnoj, Viktor|        2|\n",
            "|Anand, Viswanathan|        2|\n",
            "|    Kasimdzhanov,R|        2|\n",
            "|        Grischuk,A|        2|\n",
            "|    Short, Nigel D|        1|\n",
            "|  Spassky, Boris V|        1|\n",
            "|    Kasparov, Gary|        1|\n",
            "|  Karjakin, Sergey|        1|\n",
            "|     Timman, Jan H|        1|\n",
            "|         Svidler,P|        1|\n",
            "|         Aronian,L|        1|\n",
            "|           Anand,V|        1|\n",
            "|      Kamsky, Gata|        1|\n",
            "+------------------+---------+\n",
            "\n",
            "+--------------------+------------------+--------------------+----------+\n",
            "|             game_id|       player_name|       move_sequence|move_count|\n",
            "+--------------------+------------------+--------------------+----------+\n",
            "|4424a0a4-3732-407...|         Chernin,A|d4|d5|c4|c6|Nc3|N...|       291|\n",
            "|4424a0a4-3732-407...|       Utnasunov,A|d4|d5|c4|c6|Nc3|N...|       290|\n",
            "|58e83255-93bb-4d5...|         Carlsen,M|d4|Nf6|Nf3|d5|g3|...|       271|\n",
            "|58e83255-93bb-4d5...|  Nepomniachtchi,I|d4|Nf6|Nf3|d5|g3|...|       270|\n",
            "|88f34084-e4df-490...|         Svidler,P|Nf3|Nf6|c4|e6|d4|...|       258|\n",
            "|88f34084-e4df-490...|         Gelfand,B|Nf3|Nf6|c4|e6|d4|...|       257|\n",
            "|bf66c982-f6c5-4e7...|Kortschnoj, Viktor|c4|Nf6|d4|e6|Nc3|...|       247|\n",
            "|bf66c982-f6c5-4e7...|   Karpov, Anatoly|c4|Nf6|d4|e6|Nc3|...|       246|\n",
            "|c2ad1d49-8a47-428...|       Krasenkow,M|e4|c5|Nf3|Nc6|d4|...|       244|\n",
            "|ed4f54c2-4e7f-443...|   Carlsen, Magnus|e4|e5|Nf3|Nc6|Bb5...|       243|\n",
            "|c2ad1d49-8a47-428...|           Short,N|e4|c5|Nf3|Nc6|d4|...|       243|\n",
            "|ed4f54c2-4e7f-443...|Anand, Viswanathan|e4|e5|Nf3|Nc6|Bb5...|       242|\n",
            "|c027c41f-a2e6-4a5...|Botvinnik, Mikhail|e4|c6|d4|d5|e5|Bf...|       242|\n",
            "|c027c41f-a2e6-4a5...|       Tal, Mihail|e4|c6|d4|d5|e5|Bf...|       241|\n",
            "|1f094f29-ffeb-434...|   Lasker, Emanuel|e4|e5|Nf3|Nc6|Bb5...|       238|\n",
            "|1f094f29-ffeb-434...|Tarrasch, Siegbert|e4|e5|Nf3|Nc6|Bb5...|       237|\n",
            "|180c123b-a5e0-41f...|  Miles, Anthony J|d4|e6|Nf3|c5|c4|c...|       236|\n",
            "|180c123b-a5e0-41f...| Krasenkow, Michal|d4|e6|Nf3|c5|c4|c...|       235|\n",
            "|99d39a93-427e-4d1...|  Caruana, Fabiano|e4|c5|Nf3|Nc6|Bb5...|       229|\n",
            "|99d39a93-427e-4d1...|   Carlsen, Magnus|e4|c5|Nf3|Nc6|Bb5...|       228|\n",
            "+--------------------+------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---------------------+\n",
            "|total_number_of_games|\n",
            "+---------------------+\n",
            "|                   50|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}